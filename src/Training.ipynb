{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doHg89WNucOG"
      },
      "outputs": [],
      "source": [
        "# Install additional required libraries\n",
        "!pip install tensorFlow\n",
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFIV4EVHuviP"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy\n",
        "import sys\n",
        "sys.maxsize\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZm5Jej0ZlvB"
      },
      "outputs": [],
      "source": [
        "# Import ANFIS implementation to be used\n",
        "import myanfis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "8iy1taaIxBpJ",
        "outputId": "b827af5f-6e50-4b6e-f148-b55d24c63eef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VarName1</th>\n",
              "      <th>ORIGINE_1</th>\n",
              "      <th>ORIGINE_2</th>\n",
              "      <th>ORIGINE_3</th>\n",
              "      <th>SEXE_1</th>\n",
              "      <th>SEXE_2</th>\n",
              "      <th>IGSII_ADM_TYP_00</th>\n",
              "      <th>IGSII_ADM_TYP_60</th>\n",
              "      <th>IGSII_ADM_TYP_80</th>\n",
              "      <th>PATWGHT</th>\n",
              "      <th>...</th>\n",
              "      <th>PREBROINF0</th>\n",
              "      <th>PREBROINF1</th>\n",
              "      <th>PREBROINF2</th>\n",
              "      <th>PREBROINF3</th>\n",
              "      <th>PREBROINF4</th>\n",
              "      <th>PREBROINF5</th>\n",
              "      <th>PREBROINF6</th>\n",
              "      <th>PREBROINF7</th>\n",
              "      <th>ANTIBIOTIC</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   VarName1  ORIGINE_1  ORIGINE_2  ORIGINE_3  SEXE_1  SEXE_2  \\\n",
              "0         0          0          1          0       1       0   \n",
              "1         2          1          0          0       1       0   \n",
              "2         3          0          0          1       1       0   \n",
              "3         6          0          1          0       1       0   \n",
              "4         9          1          0          0       0       1   \n",
              "\n",
              "   IGSII_ADM_TYP_00  IGSII_ADM_TYP_60  IGSII_ADM_TYP_80  PATWGHT  ...  \\\n",
              "0                 0                 1                 0       80  ...   \n",
              "1                 0                 1                 0       73  ...   \n",
              "2                 0                 1                 0       80  ...   \n",
              "3                 0                 1                 0       50  ...   \n",
              "4                 0                 1                 0       79  ...   \n",
              "\n",
              "   PREBROINF0  PREBROINF1  PREBROINF2  PREBROINF3  PREBROINF4  PREBROINF5  \\\n",
              "0           0           0           0           0           0           0   \n",
              "1           1           0           0           0           0           0   \n",
              "2           1           0           0           1           0           0   \n",
              "3           0           0           0           0           1           0   \n",
              "4           0           0           0           0           0           0   \n",
              "\n",
              "   PREBROINF6  PREBROINF7  ANTIBIOTIC  label  \n",
              "0           0           0           1      0  \n",
              "1           0           0           1      0  \n",
              "2           0           0           1      0  \n",
              "3           0           0           0      0  \n",
              "4           0           0           1      0  \n",
              "\n",
              "[5 rows x 128 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import data\n",
        "df = pd.read_csv('data.csv', header=[0])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1gv3nw6lx0hO",
        "outputId": "e6216526-1962-4a15-e1e9-989fd3577417"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e533dbe-5232-4ca9-b84d-faf4081dbd65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGINE_1</th>\n",
              "      <th>ORIGINE_2</th>\n",
              "      <th>ORIGINE_3</th>\n",
              "      <th>SEXE_1</th>\n",
              "      <th>SEXE_2</th>\n",
              "      <th>AGE</th>\n",
              "      <th>SOFA_INC2</th>\n",
              "      <th>SOFA_ADM</th>\n",
              "      <th>IGS3_ADM</th>\n",
              "      <th>GLYCEMIE</th>\n",
              "      <th>LACTATES_J0</th>\n",
              "      <th>Cort_DiffMax</th>\n",
              "      <th>My_AR_INF_Type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.594406</td>\n",
              "      <td>0.217460</td>\n",
              "      <td>0.106667</td>\n",
              "      <td>0.173194</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.741259</td>\n",
              "      <td>0.242857</td>\n",
              "      <td>0.049333</td>\n",
              "      <td>0.159649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.243590</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.482517</td>\n",
              "      <td>0.296825</td>\n",
              "      <td>0.047994</td>\n",
              "      <td>0.147308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.664336</td>\n",
              "      <td>0.160317</td>\n",
              "      <td>0.081333</td>\n",
              "      <td>0.137122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.179487</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.489510</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.179042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e533dbe-5232-4ca9-b84d-faf4081dbd65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e533dbe-5232-4ca9-b84d-faf4081dbd65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e533dbe-5232-4ca9-b84d-faf4081dbd65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ORIGINE_1  ORIGINE_2  ORIGINE_3  SEXE_1  SEXE_2       AGE  SOFA_INC2  \\\n",
              "0        0.0        1.0        0.0     1.0     0.0  0.833333       0.40   \n",
              "1        1.0        0.0        0.0     1.0     0.0  0.846154       0.45   \n",
              "2        0.0        0.0        1.0     1.0     0.0  0.243590       0.25   \n",
              "3        0.0        1.0        0.0     1.0     0.0  0.500000       0.65   \n",
              "4        1.0        0.0        0.0     0.0     1.0  0.179487       0.35   \n",
              "\n",
              "   SOFA_ADM  IGS3_ADM  GLYCEMIE  LACTATES_J0  Cort_DiffMax  My_AR_INF_Type  \\\n",
              "0  0.391304  0.594406  0.217460     0.106667      0.173194             1.0   \n",
              "1  0.608696  0.741259  0.242857     0.049333      0.159649             0.0   \n",
              "2  0.130435  0.482517  0.296825     0.047994      0.147308             0.0   \n",
              "3  0.391304  0.664336  0.160317     0.081333      0.137122             0.0   \n",
              "4  0.521739  0.489510  0.228571     0.044000      0.179042             0.0   \n",
              "\n",
              "   label  \n",
              "0    0.0  \n",
              "1    0.0  \n",
              "2    0.0  \n",
              "3    0.0  \n",
              "4    0.0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minmaxScaler = MinMaxScaler()\n",
        "\n",
        "df2 = df.copy()\n",
        "\n",
        "# Reduce data to best 13 feautures needed\n",
        "\n",
        "chosen = ['AGE', 'SEXE_1', 'SEXE_2', 'LACTATES_J0', 'IGS3_ADM', 'My_AR_INF_Type', 'SOFA_INC2', 'Cort_DiffMax', 'GLYCEMIE', 'SOFA_ADM', 'ORIGINE_1', 'ORIGINE_2', 'ORIGINE_3', 'label']\n",
        "for col in df2.columns:\n",
        "    if col not in chosen:\n",
        "        df2.drop(col, inplace=True, axis=1)\n",
        "\n",
        "# Scaling features into 0-1\n",
        "\n",
        "df2[df2.columns] = minmaxScaler.fit_transform(df2[df2.columns])\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "7SOGe1_myBed",
        "outputId": "696260f9-1c19-43a7-8930-557ea6598015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X before SMOTE: (570, 13)\n",
            "Shape of X after SMOTE: (716, 13)\n",
            "\n",
            "Balance of positive and negative classes (%):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-975f15ad-4796-49d2-972f-800de71408f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGINE_1</th>\n",
              "      <th>ORIGINE_2</th>\n",
              "      <th>ORIGINE_3</th>\n",
              "      <th>SEXE_1</th>\n",
              "      <th>SEXE_2</th>\n",
              "      <th>AGE</th>\n",
              "      <th>SOFA_INC2</th>\n",
              "      <th>SOFA_ADM</th>\n",
              "      <th>IGS3_ADM</th>\n",
              "      <th>GLYCEMIE</th>\n",
              "      <th>LACTATES_J0</th>\n",
              "      <th>Cort_DiffMax</th>\n",
              "      <th>My_AR_INF_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104762</td>\n",
              "      <td>0.102667</td>\n",
              "      <td>0.142391</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.628205</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.247619</td>\n",
              "      <td>0.068000</td>\n",
              "      <td>0.132029</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.215873</td>\n",
              "      <td>0.030667</td>\n",
              "      <td>0.132029</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134921</td>\n",
              "      <td>0.085333</td>\n",
              "      <td>0.132029</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.487179</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120635</td>\n",
              "      <td>0.074667</td>\n",
              "      <td>0.132029</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-975f15ad-4796-49d2-972f-800de71408f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-975f15ad-4796-49d2-972f-800de71408f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-975f15ad-4796-49d2-972f-800de71408f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ORIGINE_1  ORIGINE_2  ORIGINE_3  SEXE_1  SEXE_2       AGE  SOFA_INC2  \\\n",
              "0        1.0        0.0        0.0     1.0     0.0  0.820513       0.50   \n",
              "1        0.0        1.0        0.0     1.0     0.0  0.628205       0.80   \n",
              "2        1.0        0.0        0.0     1.0     0.0  0.858974       0.40   \n",
              "3        1.0        0.0        0.0     0.0     1.0  0.974359       0.35   \n",
              "4        0.0        0.0        1.0     1.0     0.0  0.487179       0.70   \n",
              "\n",
              "   SOFA_ADM  IGS3_ADM  GLYCEMIE  LACTATES_J0  Cort_DiffMax  My_AR_INF_Type  \n",
              "0  0.434783       0.0  0.104762     0.102667      0.142391             0.0  \n",
              "1  0.434783       0.0  0.247619     0.068000      0.132029             1.0  \n",
              "2  0.391304       0.0  0.215873     0.030667      0.132029             1.0  \n",
              "3  0.565217       0.0  0.134921     0.085333      0.132029             0.0  \n",
              "4  0.652174       0.0  0.120635     0.074667      0.132029             0.0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split data into training and validation sets\n",
        "#training\n",
        "X_train = df2.iloc[:570,:13]\n",
        "Y_train = df2.iloc[:570,-1]\n",
        "\n",
        "# validation\n",
        "X_test = df2.iloc[570:,:13]\n",
        "Y_test = df2.iloc[570:,-1]\n",
        "\n",
        "# Reduce overfitting and fix unbalanced data problem\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "\n",
        "X_sm, Y_sm = sm.fit_resample(X_train, Y_train)\n",
        "\n",
        "print(f'''Shape of X before SMOTE: {X_train.shape}\n",
        "Shape of X after SMOTE: {X_sm.shape}''')\n",
        "\n",
        "print('\\nBalance of positive and negative classes (%):')\n",
        "Y_sm.value_counts(normalize=True) * 100\n",
        "\n",
        "X_test, Y_test = sm.fit_resample(X_test, Y_test)\n",
        "\n",
        "X_train=X_sm\n",
        "Y_train=Y_sm\n",
        "\n",
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMcpKm5dyeAC"
      },
      "outputs": [],
      "source": [
        "# Setting ANFIS parameters\n",
        "\n",
        "param = myanfis.fis_parameters(\n",
        "        n_input = 13,                # no. of Regressors\n",
        "        n_memb = 2,                 # no. of fuzzy memberships\n",
        "        batch_size = 1,\n",
        "        memb_func = 'sigmoid',      # 'gaussian' / 'gbellmf' / 'sigmoid'\n",
        "        optimizer = 'adam',          # sgd / adam / ...\n",
        "        loss = tf.keras.losses.MeanSquaredError(),               # tf.keras.losses.MeanAbsoluteError(), mse / mae / huber_loss / mean_absolute_percentage_error / ...\n",
        "        n_epochs = 500\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSV452G1aPx_",
        "outputId": "ced8c695-8721-4b81-8f43-4de29e7e862b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "716/716 [==============================] - 5s 5ms/step - loss: 0.2811 - accuracy: 0.5056 - val_loss: 0.2609 - val_accuracy: 0.5227\n",
            "Epoch 2/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2459 - accuracy: 0.5237 - val_loss: 0.2394 - val_accuracy: 0.5682\n",
            "Epoch 3/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2304 - accuracy: 0.6131 - val_loss: 0.2255 - val_accuracy: 0.6591\n",
            "Epoch 4/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2209 - accuracy: 0.6383 - val_loss: 0.2168 - val_accuracy: 0.5909\n",
            "Epoch 5/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2160 - accuracy: 0.6662 - val_loss: 0.2094 - val_accuracy: 0.6818\n",
            "Epoch 6/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2112 - accuracy: 0.6620 - val_loss: 0.2015 - val_accuracy: 0.7045\n",
            "Epoch 7/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.2082 - accuracy: 0.6676 - val_loss: 0.2013 - val_accuracy: 0.7500\n",
            "Epoch 8/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2058 - accuracy: 0.6718 - val_loss: 0.1963 - val_accuracy: 0.6818\n",
            "Epoch 9/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2050 - accuracy: 0.6899 - val_loss: 0.1960 - val_accuracy: 0.7045\n",
            "Epoch 10/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2030 - accuracy: 0.6816 - val_loss: 0.1931 - val_accuracy: 0.6591\n",
            "Epoch 11/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2030 - accuracy: 0.6899 - val_loss: 0.1946 - val_accuracy: 0.7045\n",
            "Epoch 12/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.2007 - accuracy: 0.6760 - val_loss: 0.1982 - val_accuracy: 0.6818\n",
            "Epoch 13/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1991 - accuracy: 0.6885 - val_loss: 0.1924 - val_accuracy: 0.7045\n",
            "Epoch 14/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1981 - accuracy: 0.6802 - val_loss: 0.1959 - val_accuracy: 0.6818\n",
            "Epoch 15/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1980 - accuracy: 0.6941 - val_loss: 0.1938 - val_accuracy: 0.7273\n",
            "Epoch 16/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1974 - accuracy: 0.6885 - val_loss: 0.1965 - val_accuracy: 0.7045\n",
            "Epoch 17/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1966 - accuracy: 0.6885 - val_loss: 0.2080 - val_accuracy: 0.6818\n",
            "Epoch 18/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1964 - accuracy: 0.6816 - val_loss: 0.2033 - val_accuracy: 0.6818\n",
            "Epoch 19/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1959 - accuracy: 0.6844 - val_loss: 0.1946 - val_accuracy: 0.7045\n",
            "Epoch 20/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1942 - accuracy: 0.6969 - val_loss: 0.1951 - val_accuracy: 0.7045\n",
            "Epoch 21/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1942 - accuracy: 0.6872 - val_loss: 0.1971 - val_accuracy: 0.7273\n",
            "Epoch 22/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1941 - accuracy: 0.6983 - val_loss: 0.1915 - val_accuracy: 0.7273\n",
            "Epoch 23/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1931 - accuracy: 0.6913 - val_loss: 0.1967 - val_accuracy: 0.7273\n",
            "Epoch 24/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1933 - accuracy: 0.6788 - val_loss: 0.1987 - val_accuracy: 0.7273\n",
            "Epoch 25/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1927 - accuracy: 0.7067 - val_loss: 0.1955 - val_accuracy: 0.6818\n",
            "Epoch 26/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1918 - accuracy: 0.6913 - val_loss: 0.1955 - val_accuracy: 0.7045\n",
            "Epoch 27/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1902 - accuracy: 0.6913 - val_loss: 0.1915 - val_accuracy: 0.7045\n",
            "Epoch 28/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1905 - accuracy: 0.7277 - val_loss: 0.2028 - val_accuracy: 0.6818\n",
            "Epoch 29/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1899 - accuracy: 0.7053 - val_loss: 0.1931 - val_accuracy: 0.6818\n",
            "Epoch 30/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1891 - accuracy: 0.7221 - val_loss: 0.1928 - val_accuracy: 0.6591\n",
            "Epoch 31/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1898 - accuracy: 0.7123 - val_loss: 0.2014 - val_accuracy: 0.6818\n",
            "Epoch 32/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1882 - accuracy: 0.7151 - val_loss: 0.1967 - val_accuracy: 0.7045\n",
            "Epoch 33/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1883 - accuracy: 0.6955 - val_loss: 0.1938 - val_accuracy: 0.7045\n",
            "Epoch 34/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1884 - accuracy: 0.7277 - val_loss: 0.2011 - val_accuracy: 0.7045\n",
            "Epoch 35/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1878 - accuracy: 0.7053 - val_loss: 0.1977 - val_accuracy: 0.6818\n",
            "Epoch 36/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1882 - accuracy: 0.7193 - val_loss: 0.1970 - val_accuracy: 0.7045\n",
            "Epoch 37/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1874 - accuracy: 0.7151 - val_loss: 0.1913 - val_accuracy: 0.7273\n",
            "Epoch 38/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1865 - accuracy: 0.7179 - val_loss: 0.2029 - val_accuracy: 0.6818\n",
            "Epoch 39/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1851 - accuracy: 0.7137 - val_loss: 0.2063 - val_accuracy: 0.6591\n",
            "Epoch 40/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1864 - accuracy: 0.6997 - val_loss: 0.2067 - val_accuracy: 0.6591\n",
            "Epoch 41/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1860 - accuracy: 0.7277 - val_loss: 0.1943 - val_accuracy: 0.6818\n",
            "Epoch 42/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1849 - accuracy: 0.7346 - val_loss: 0.2155 - val_accuracy: 0.6364\n",
            "Epoch 43/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1842 - accuracy: 0.7179 - val_loss: 0.1927 - val_accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1862 - accuracy: 0.7137 - val_loss: 0.1932 - val_accuracy: 0.7045\n",
            "Epoch 45/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1847 - accuracy: 0.7277 - val_loss: 0.1940 - val_accuracy: 0.6818\n",
            "Epoch 46/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1829 - accuracy: 0.7277 - val_loss: 0.1976 - val_accuracy: 0.6818\n",
            "Epoch 47/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1837 - accuracy: 0.7346 - val_loss: 0.1950 - val_accuracy: 0.6818\n",
            "Epoch 48/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1840 - accuracy: 0.7318 - val_loss: 0.1909 - val_accuracy: 0.7273\n",
            "Epoch 49/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1828 - accuracy: 0.7277 - val_loss: 0.1894 - val_accuracy: 0.7045\n",
            "Epoch 50/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1826 - accuracy: 0.7304 - val_loss: 0.1991 - val_accuracy: 0.6818\n",
            "Epoch 51/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1826 - accuracy: 0.7374 - val_loss: 0.1913 - val_accuracy: 0.7273\n",
            "Epoch 52/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1825 - accuracy: 0.7388 - val_loss: 0.1966 - val_accuracy: 0.6818\n",
            "Epoch 53/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1811 - accuracy: 0.7207 - val_loss: 0.2137 - val_accuracy: 0.6364\n",
            "Epoch 54/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1818 - accuracy: 0.7277 - val_loss: 0.2038 - val_accuracy: 0.6591\n",
            "Epoch 55/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1811 - accuracy: 0.7458 - val_loss: 0.2010 - val_accuracy: 0.6818\n",
            "Epoch 56/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1809 - accuracy: 0.7388 - val_loss: 0.1933 - val_accuracy: 0.6818\n",
            "Epoch 57/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1807 - accuracy: 0.7430 - val_loss: 0.2013 - val_accuracy: 0.6591\n",
            "Epoch 58/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1805 - accuracy: 0.7374 - val_loss: 0.1926 - val_accuracy: 0.7273\n",
            "Epoch 59/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1804 - accuracy: 0.7318 - val_loss: 0.1943 - val_accuracy: 0.6364\n",
            "Epoch 60/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1800 - accuracy: 0.7318 - val_loss: 0.2002 - val_accuracy: 0.6591\n",
            "Epoch 61/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1790 - accuracy: 0.7207 - val_loss: 0.2092 - val_accuracy: 0.6591\n",
            "Epoch 62/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1797 - accuracy: 0.7388 - val_loss: 0.1993 - val_accuracy: 0.7273\n",
            "Epoch 63/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1785 - accuracy: 0.7402 - val_loss: 0.1959 - val_accuracy: 0.6818\n",
            "Epoch 64/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1787 - accuracy: 0.7416 - val_loss: 0.1962 - val_accuracy: 0.7045\n",
            "Epoch 65/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1779 - accuracy: 0.7249 - val_loss: 0.2077 - val_accuracy: 0.6591\n",
            "Epoch 66/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1783 - accuracy: 0.7332 - val_loss: 0.1989 - val_accuracy: 0.6818\n",
            "Epoch 67/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1777 - accuracy: 0.7318 - val_loss: 0.1973 - val_accuracy: 0.7273\n",
            "Epoch 68/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1773 - accuracy: 0.7416 - val_loss: 0.1987 - val_accuracy: 0.7045\n",
            "Epoch 69/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1771 - accuracy: 0.7444 - val_loss: 0.1973 - val_accuracy: 0.7273\n",
            "Epoch 70/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1781 - accuracy: 0.7402 - val_loss: 0.1994 - val_accuracy: 0.6818\n",
            "Epoch 71/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1770 - accuracy: 0.7514 - val_loss: 0.2061 - val_accuracy: 0.6818\n",
            "Epoch 72/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1746 - accuracy: 0.7668 - val_loss: 0.2157 - val_accuracy: 0.6364\n",
            "Epoch 73/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1765 - accuracy: 0.7528 - val_loss: 0.2052 - val_accuracy: 0.6818\n",
            "Epoch 74/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1759 - accuracy: 0.7346 - val_loss: 0.2026 - val_accuracy: 0.6818\n",
            "Epoch 75/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1743 - accuracy: 0.7472 - val_loss: 0.1971 - val_accuracy: 0.7045\n",
            "Epoch 76/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1742 - accuracy: 0.7444 - val_loss: 0.1922 - val_accuracy: 0.6818\n",
            "Epoch 77/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1759 - accuracy: 0.7360 - val_loss: 0.1962 - val_accuracy: 0.7273\n",
            "Epoch 78/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1749 - accuracy: 0.7402 - val_loss: 0.1984 - val_accuracy: 0.7500\n",
            "Epoch 79/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1742 - accuracy: 0.7500 - val_loss: 0.2016 - val_accuracy: 0.7273\n",
            "Epoch 80/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1735 - accuracy: 0.7416 - val_loss: 0.1977 - val_accuracy: 0.7500\n",
            "Epoch 81/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1748 - accuracy: 0.7598 - val_loss: 0.2088 - val_accuracy: 0.6591\n",
            "Epoch 82/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1741 - accuracy: 0.7500 - val_loss: 0.2045 - val_accuracy: 0.6818\n",
            "Epoch 83/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1734 - accuracy: 0.7388 - val_loss: 0.1939 - val_accuracy: 0.7273\n",
            "Epoch 84/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1737 - accuracy: 0.7486 - val_loss: 0.2005 - val_accuracy: 0.7045\n",
            "Epoch 85/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1735 - accuracy: 0.7500 - val_loss: 0.1957 - val_accuracy: 0.7500\n",
            "Epoch 86/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1723 - accuracy: 0.7444 - val_loss: 0.1949 - val_accuracy: 0.7273\n",
            "Epoch 87/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1730 - accuracy: 0.7542 - val_loss: 0.2013 - val_accuracy: 0.6818\n",
            "Epoch 88/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1717 - accuracy: 0.7514 - val_loss: 0.2092 - val_accuracy: 0.6364\n",
            "Epoch 89/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1724 - accuracy: 0.7584 - val_loss: 0.1987 - val_accuracy: 0.6818\n",
            "Epoch 90/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1711 - accuracy: 0.7472 - val_loss: 0.1997 - val_accuracy: 0.7273\n",
            "Epoch 91/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1719 - accuracy: 0.7514 - val_loss: 0.2060 - val_accuracy: 0.6818\n",
            "Epoch 92/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1711 - accuracy: 0.7444 - val_loss: 0.2045 - val_accuracy: 0.6818\n",
            "Epoch 93/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1712 - accuracy: 0.7542 - val_loss: 0.1932 - val_accuracy: 0.7500\n",
            "Epoch 94/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1703 - accuracy: 0.7514 - val_loss: 0.1942 - val_accuracy: 0.6818\n",
            "Epoch 95/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1709 - accuracy: 0.7542 - val_loss: 0.2097 - val_accuracy: 0.6818\n",
            "Epoch 96/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1699 - accuracy: 0.7696 - val_loss: 0.1964 - val_accuracy: 0.7273\n",
            "Epoch 97/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1693 - accuracy: 0.7626 - val_loss: 0.1953 - val_accuracy: 0.6364\n",
            "Epoch 98/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1705 - accuracy: 0.7486 - val_loss: 0.2082 - val_accuracy: 0.7273\n",
            "Epoch 99/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1677 - accuracy: 0.7584 - val_loss: 0.2101 - val_accuracy: 0.6591\n",
            "Epoch 100/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1696 - accuracy: 0.7458 - val_loss: 0.1995 - val_accuracy: 0.7045\n",
            "Epoch 101/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1685 - accuracy: 0.7528 - val_loss: 0.1999 - val_accuracy: 0.7273\n",
            "Epoch 102/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1688 - accuracy: 0.7570 - val_loss: 0.1958 - val_accuracy: 0.6818\n",
            "Epoch 103/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1672 - accuracy: 0.7612 - val_loss: 0.2030 - val_accuracy: 0.6818\n",
            "Epoch 104/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1677 - accuracy: 0.7528 - val_loss: 0.1885 - val_accuracy: 0.7045\n",
            "Epoch 105/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1679 - accuracy: 0.7654 - val_loss: 0.2035 - val_accuracy: 0.7045\n",
            "Epoch 106/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1670 - accuracy: 0.7668 - val_loss: 0.1923 - val_accuracy: 0.7273\n",
            "Epoch 107/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1673 - accuracy: 0.7654 - val_loss: 0.2016 - val_accuracy: 0.7273\n",
            "Epoch 108/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1663 - accuracy: 0.7668 - val_loss: 0.1956 - val_accuracy: 0.7500\n",
            "Epoch 109/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1663 - accuracy: 0.7598 - val_loss: 0.1933 - val_accuracy: 0.7273\n",
            "Epoch 110/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1677 - accuracy: 0.7584 - val_loss: 0.1948 - val_accuracy: 0.6818\n",
            "Epoch 111/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1655 - accuracy: 0.7751 - val_loss: 0.1944 - val_accuracy: 0.7045\n",
            "Epoch 112/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1656 - accuracy: 0.7640 - val_loss: 0.2093 - val_accuracy: 0.6818\n",
            "Epoch 113/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1646 - accuracy: 0.7556 - val_loss: 0.1922 - val_accuracy: 0.7273\n",
            "Epoch 114/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1642 - accuracy: 0.7696 - val_loss: 0.2165 - val_accuracy: 0.6818\n",
            "Epoch 115/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1659 - accuracy: 0.7528 - val_loss: 0.2036 - val_accuracy: 0.6591\n",
            "Epoch 116/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1653 - accuracy: 0.7640 - val_loss: 0.2019 - val_accuracy: 0.6818\n",
            "Epoch 117/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1647 - accuracy: 0.7584 - val_loss: 0.2021 - val_accuracy: 0.7273\n",
            "Epoch 118/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1640 - accuracy: 0.7542 - val_loss: 0.2076 - val_accuracy: 0.7045\n",
            "Epoch 119/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1636 - accuracy: 0.7668 - val_loss: 0.2122 - val_accuracy: 0.6818\n",
            "Epoch 120/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1646 - accuracy: 0.7612 - val_loss: 0.1989 - val_accuracy: 0.7045\n",
            "Epoch 121/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1638 - accuracy: 0.7709 - val_loss: 0.2007 - val_accuracy: 0.6818\n",
            "Epoch 122/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1629 - accuracy: 0.7696 - val_loss: 0.2035 - val_accuracy: 0.7045\n",
            "Epoch 123/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1629 - accuracy: 0.7696 - val_loss: 0.1808 - val_accuracy: 0.6818\n",
            "Epoch 124/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1638 - accuracy: 0.7709 - val_loss: 0.1914 - val_accuracy: 0.6818\n",
            "Epoch 125/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1642 - accuracy: 0.7640 - val_loss: 0.1984 - val_accuracy: 0.7500\n",
            "Epoch 126/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1631 - accuracy: 0.7612 - val_loss: 0.1930 - val_accuracy: 0.6818\n",
            "Epoch 127/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1628 - accuracy: 0.7765 - val_loss: 0.1883 - val_accuracy: 0.7273\n",
            "Epoch 128/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1619 - accuracy: 0.7765 - val_loss: 0.2302 - val_accuracy: 0.7045\n",
            "Epoch 129/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1631 - accuracy: 0.7737 - val_loss: 0.2103 - val_accuracy: 0.6818\n",
            "Epoch 130/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1623 - accuracy: 0.7779 - val_loss: 0.1921 - val_accuracy: 0.7045\n",
            "Epoch 131/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1616 - accuracy: 0.7542 - val_loss: 0.2046 - val_accuracy: 0.6818\n",
            "Epoch 132/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.7737 - val_loss: 0.1985 - val_accuracy: 0.6818\n",
            "Epoch 133/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1615 - accuracy: 0.7835 - val_loss: 0.1856 - val_accuracy: 0.7273\n",
            "Epoch 134/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1607 - accuracy: 0.7737 - val_loss: 0.2014 - val_accuracy: 0.7045\n",
            "Epoch 135/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1605 - accuracy: 0.7723 - val_loss: 0.1975 - val_accuracy: 0.7045\n",
            "Epoch 136/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1610 - accuracy: 0.7654 - val_loss: 0.2087 - val_accuracy: 0.7045\n",
            "Epoch 137/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1601 - accuracy: 0.7779 - val_loss: 0.1923 - val_accuracy: 0.7273\n",
            "Epoch 138/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1597 - accuracy: 0.7696 - val_loss: 0.1924 - val_accuracy: 0.7273\n",
            "Epoch 139/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1600 - accuracy: 0.7556 - val_loss: 0.1877 - val_accuracy: 0.7045\n",
            "Epoch 140/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1603 - accuracy: 0.7682 - val_loss: 0.1996 - val_accuracy: 0.7273\n",
            "Epoch 141/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1580 - accuracy: 0.7751 - val_loss: 0.1905 - val_accuracy: 0.7045\n",
            "Epoch 142/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1597 - accuracy: 0.7723 - val_loss: 0.2016 - val_accuracy: 0.7045\n",
            "Epoch 143/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1592 - accuracy: 0.7682 - val_loss: 0.1999 - val_accuracy: 0.7273\n",
            "Epoch 144/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1585 - accuracy: 0.7779 - val_loss: 0.1978 - val_accuracy: 0.7045\n",
            "Epoch 145/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1582 - accuracy: 0.7737 - val_loss: 0.2125 - val_accuracy: 0.7045\n",
            "Epoch 146/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1579 - accuracy: 0.7723 - val_loss: 0.1981 - val_accuracy: 0.6818\n",
            "Epoch 147/500\n",
            "716/716 [==============================] - 5s 7ms/step - loss: 0.1561 - accuracy: 0.7835 - val_loss: 0.2211 - val_accuracy: 0.6818\n",
            "Epoch 148/500\n",
            "716/716 [==============================] - 6s 8ms/step - loss: 0.1592 - accuracy: 0.7779 - val_loss: 0.2014 - val_accuracy: 0.7045\n",
            "Epoch 149/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1584 - accuracy: 0.7696 - val_loss: 0.1965 - val_accuracy: 0.7273\n",
            "Epoch 150/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1575 - accuracy: 0.7654 - val_loss: 0.2011 - val_accuracy: 0.7045\n",
            "Epoch 151/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1578 - accuracy: 0.7793 - val_loss: 0.1899 - val_accuracy: 0.7500\n",
            "Epoch 152/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1573 - accuracy: 0.7709 - val_loss: 0.1928 - val_accuracy: 0.7273\n",
            "Epoch 153/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1571 - accuracy: 0.7905 - val_loss: 0.1971 - val_accuracy: 0.7045\n",
            "Epoch 154/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1565 - accuracy: 0.7765 - val_loss: 0.2003 - val_accuracy: 0.7045\n",
            "Epoch 155/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1559 - accuracy: 0.7779 - val_loss: 0.2009 - val_accuracy: 0.7045\n",
            "Epoch 156/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1548 - accuracy: 0.7737 - val_loss: 0.1891 - val_accuracy: 0.6818\n",
            "Epoch 157/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1569 - accuracy: 0.7612 - val_loss: 0.2051 - val_accuracy: 0.7045\n",
            "Epoch 158/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1557 - accuracy: 0.7863 - val_loss: 0.1929 - val_accuracy: 0.7273\n",
            "Epoch 159/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1560 - accuracy: 0.7779 - val_loss: 0.2015 - val_accuracy: 0.6818\n",
            "Epoch 160/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.7807 - val_loss: 0.1918 - val_accuracy: 0.7273\n",
            "Epoch 161/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1558 - accuracy: 0.7835 - val_loss: 0.2062 - val_accuracy: 0.7045\n",
            "Epoch 162/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1555 - accuracy: 0.7821 - val_loss: 0.1897 - val_accuracy: 0.7273\n",
            "Epoch 163/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1545 - accuracy: 0.7751 - val_loss: 0.1864 - val_accuracy: 0.7045\n",
            "Epoch 164/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1525 - accuracy: 0.7737 - val_loss: 0.2129 - val_accuracy: 0.7045\n",
            "Epoch 165/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1548 - accuracy: 0.7765 - val_loss: 0.1907 - val_accuracy: 0.7500\n",
            "Epoch 166/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1536 - accuracy: 0.7779 - val_loss: 0.2049 - val_accuracy: 0.7045\n",
            "Epoch 167/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1536 - accuracy: 0.7709 - val_loss: 0.1927 - val_accuracy: 0.7273\n",
            "Epoch 168/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1543 - accuracy: 0.7696 - val_loss: 0.1893 - val_accuracy: 0.7727\n",
            "Epoch 169/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1545 - accuracy: 0.7779 - val_loss: 0.1845 - val_accuracy: 0.7045\n",
            "Epoch 170/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1533 - accuracy: 0.7793 - val_loss: 0.1873 - val_accuracy: 0.7500\n",
            "Epoch 171/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.7849 - val_loss: 0.1893 - val_accuracy: 0.7500\n",
            "Epoch 172/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1527 - accuracy: 0.7989 - val_loss: 0.2039 - val_accuracy: 0.7045\n",
            "Epoch 173/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1530 - accuracy: 0.7793 - val_loss: 0.1919 - val_accuracy: 0.7273\n",
            "Epoch 174/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1531 - accuracy: 0.7779 - val_loss: 0.1905 - val_accuracy: 0.7273\n",
            "Epoch 175/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1524 - accuracy: 0.7807 - val_loss: 0.1996 - val_accuracy: 0.7045\n",
            "Epoch 176/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1509 - accuracy: 0.7905 - val_loss: 0.1951 - val_accuracy: 0.7500\n",
            "Epoch 177/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1514 - accuracy: 0.7821 - val_loss: 0.1903 - val_accuracy: 0.7273\n",
            "Epoch 178/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1512 - accuracy: 0.7765 - val_loss: 0.1747 - val_accuracy: 0.7727\n",
            "Epoch 179/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.7905 - val_loss: 0.2011 - val_accuracy: 0.7273\n",
            "Epoch 180/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1518 - accuracy: 0.7835 - val_loss: 0.1944 - val_accuracy: 0.7273\n",
            "Epoch 181/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1510 - accuracy: 0.7877 - val_loss: 0.2003 - val_accuracy: 0.7045\n",
            "Epoch 182/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1516 - accuracy: 0.7877 - val_loss: 0.2009 - val_accuracy: 0.7045\n",
            "Epoch 183/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1516 - accuracy: 0.7793 - val_loss: 0.1845 - val_accuracy: 0.7273\n",
            "Epoch 184/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1503 - accuracy: 0.7863 - val_loss: 0.1884 - val_accuracy: 0.7273\n",
            "Epoch 185/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1501 - accuracy: 0.7919 - val_loss: 0.2032 - val_accuracy: 0.7045\n",
            "Epoch 186/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1500 - accuracy: 0.7877 - val_loss: 0.2035 - val_accuracy: 0.7045\n",
            "Epoch 187/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1500 - accuracy: 0.7849 - val_loss: 0.1826 - val_accuracy: 0.7500\n",
            "Epoch 188/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1497 - accuracy: 0.7933 - val_loss: 0.1884 - val_accuracy: 0.7273\n",
            "Epoch 189/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1495 - accuracy: 0.7835 - val_loss: 0.2017 - val_accuracy: 0.7045\n",
            "Epoch 190/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1485 - accuracy: 0.7891 - val_loss: 0.1899 - val_accuracy: 0.7045\n",
            "Epoch 191/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1490 - accuracy: 0.7835 - val_loss: 0.1897 - val_accuracy: 0.7273\n",
            "Epoch 192/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1491 - accuracy: 0.7863 - val_loss: 0.1864 - val_accuracy: 0.7500\n",
            "Epoch 193/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1489 - accuracy: 0.7863 - val_loss: 0.1918 - val_accuracy: 0.7273\n",
            "Epoch 194/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1489 - accuracy: 0.7835 - val_loss: 0.1950 - val_accuracy: 0.7273\n",
            "Epoch 195/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1478 - accuracy: 0.7919 - val_loss: 0.1944 - val_accuracy: 0.7045\n",
            "Epoch 196/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1487 - accuracy: 0.7863 - val_loss: 0.1835 - val_accuracy: 0.7500\n",
            "Epoch 197/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1474 - accuracy: 0.7975 - val_loss: 0.1897 - val_accuracy: 0.7273\n",
            "Epoch 198/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1475 - accuracy: 0.7863 - val_loss: 0.1846 - val_accuracy: 0.7273\n",
            "Epoch 199/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1489 - accuracy: 0.7835 - val_loss: 0.1941 - val_accuracy: 0.7045\n",
            "Epoch 200/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1477 - accuracy: 0.7877 - val_loss: 0.1966 - val_accuracy: 0.7045\n",
            "Epoch 201/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1469 - accuracy: 0.7947 - val_loss: 0.1820 - val_accuracy: 0.7955\n",
            "Epoch 202/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1463 - accuracy: 0.7877 - val_loss: 0.1903 - val_accuracy: 0.7045\n",
            "Epoch 203/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1474 - accuracy: 0.7919 - val_loss: 0.1773 - val_accuracy: 0.7727\n",
            "Epoch 204/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1471 - accuracy: 0.7905 - val_loss: 0.1943 - val_accuracy: 0.7045\n",
            "Epoch 205/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1464 - accuracy: 0.7919 - val_loss: 0.1851 - val_accuracy: 0.7273\n",
            "Epoch 206/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1445 - accuracy: 0.8003 - val_loss: 0.1881 - val_accuracy: 0.7500\n",
            "Epoch 207/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1464 - accuracy: 0.7877 - val_loss: 0.1882 - val_accuracy: 0.7045\n",
            "Epoch 208/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1465 - accuracy: 0.7919 - val_loss: 0.1899 - val_accuracy: 0.7273\n",
            "Epoch 209/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1463 - accuracy: 0.8003 - val_loss: 0.1853 - val_accuracy: 0.7500\n",
            "Epoch 210/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1460 - accuracy: 0.7849 - val_loss: 0.1855 - val_accuracy: 0.7273\n",
            "Epoch 211/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1458 - accuracy: 0.7905 - val_loss: 0.1865 - val_accuracy: 0.7273\n",
            "Epoch 212/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1446 - accuracy: 0.7919 - val_loss: 0.1872 - val_accuracy: 0.7273\n",
            "Epoch 213/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1438 - accuracy: 0.7975 - val_loss: 0.1833 - val_accuracy: 0.7500\n",
            "Epoch 214/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1437 - accuracy: 0.8031 - val_loss: 0.1866 - val_accuracy: 0.7273\n",
            "Epoch 215/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1445 - accuracy: 0.7933 - val_loss: 0.1902 - val_accuracy: 0.7045\n",
            "Epoch 216/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1445 - accuracy: 0.8003 - val_loss: 0.1936 - val_accuracy: 0.7273\n",
            "Epoch 217/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1444 - accuracy: 0.7919 - val_loss: 0.1870 - val_accuracy: 0.7273\n",
            "Epoch 218/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1432 - accuracy: 0.7905 - val_loss: 0.1949 - val_accuracy: 0.7273\n",
            "Epoch 219/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1447 - accuracy: 0.7905 - val_loss: 0.1854 - val_accuracy: 0.7273\n",
            "Epoch 220/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1441 - accuracy: 0.7947 - val_loss: 0.1811 - val_accuracy: 0.8409\n",
            "Epoch 221/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1447 - accuracy: 0.7961 - val_loss: 0.1814 - val_accuracy: 0.7273\n",
            "Epoch 222/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1435 - accuracy: 0.8003 - val_loss: 0.1933 - val_accuracy: 0.7273\n",
            "Epoch 223/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1433 - accuracy: 0.8031 - val_loss: 0.2120 - val_accuracy: 0.7273\n",
            "Epoch 224/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1436 - accuracy: 0.7961 - val_loss: 0.1894 - val_accuracy: 0.7273\n",
            "Epoch 225/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1434 - accuracy: 0.7933 - val_loss: 0.1865 - val_accuracy: 0.7500\n",
            "Epoch 226/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1428 - accuracy: 0.8087 - val_loss: 0.1840 - val_accuracy: 0.7273\n",
            "Epoch 227/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1423 - accuracy: 0.7933 - val_loss: 0.1786 - val_accuracy: 0.7273\n",
            "Epoch 228/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1426 - accuracy: 0.7989 - val_loss: 0.1900 - val_accuracy: 0.7045\n",
            "Epoch 229/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1429 - accuracy: 0.7961 - val_loss: 0.1800 - val_accuracy: 0.7045\n",
            "Epoch 230/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1410 - accuracy: 0.7975 - val_loss: 0.1986 - val_accuracy: 0.7273\n",
            "Epoch 231/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1424 - accuracy: 0.7947 - val_loss: 0.1774 - val_accuracy: 0.7727\n",
            "Epoch 232/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1421 - accuracy: 0.7933 - val_loss: 0.1892 - val_accuracy: 0.7273\n",
            "Epoch 233/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.8003 - val_loss: 0.1753 - val_accuracy: 0.7727\n",
            "Epoch 234/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.7975 - val_loss: 0.1829 - val_accuracy: 0.7273\n",
            "Epoch 235/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1409 - accuracy: 0.8184 - val_loss: 0.1742 - val_accuracy: 0.7955\n",
            "Epoch 236/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.7975 - val_loss: 0.1794 - val_accuracy: 0.7500\n",
            "Epoch 237/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1418 - accuracy: 0.8045 - val_loss: 0.1840 - val_accuracy: 0.7727\n",
            "Epoch 238/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1411 - accuracy: 0.7891 - val_loss: 0.2009 - val_accuracy: 0.7045\n",
            "Epoch 239/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1409 - accuracy: 0.7919 - val_loss: 0.1736 - val_accuracy: 0.7955\n",
            "Epoch 240/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1398 - accuracy: 0.8073 - val_loss: 0.1895 - val_accuracy: 0.7727\n",
            "Epoch 241/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1416 - accuracy: 0.7947 - val_loss: 0.1799 - val_accuracy: 0.7727\n",
            "Epoch 242/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.8031 - val_loss: 0.1771 - val_accuracy: 0.7727\n",
            "Epoch 243/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1406 - accuracy: 0.8087 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
            "Epoch 244/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1419 - accuracy: 0.8031 - val_loss: 0.1848 - val_accuracy: 0.7500\n",
            "Epoch 245/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1404 - accuracy: 0.8045 - val_loss: 0.1820 - val_accuracy: 0.7500\n",
            "Epoch 246/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1397 - accuracy: 0.8115 - val_loss: 0.1760 - val_accuracy: 0.7500\n",
            "Epoch 247/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1390 - accuracy: 0.8059 - val_loss: 0.1767 - val_accuracy: 0.7955\n",
            "Epoch 248/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.8073 - val_loss: 0.1872 - val_accuracy: 0.7273\n",
            "Epoch 249/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1405 - accuracy: 0.8003 - val_loss: 0.1883 - val_accuracy: 0.7045\n",
            "Epoch 250/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1396 - accuracy: 0.8073 - val_loss: 0.1765 - val_accuracy: 0.7955\n",
            "Epoch 251/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1386 - accuracy: 0.8087 - val_loss: 0.1861 - val_accuracy: 0.7273\n",
            "Epoch 252/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.7989 - val_loss: 0.1780 - val_accuracy: 0.7500\n",
            "Epoch 253/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1390 - accuracy: 0.7933 - val_loss: 0.1873 - val_accuracy: 0.7273\n",
            "Epoch 254/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1393 - accuracy: 0.8045 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
            "Epoch 255/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.8128 - val_loss: 0.1842 - val_accuracy: 0.7273\n",
            "Epoch 256/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1391 - accuracy: 0.7947 - val_loss: 0.1692 - val_accuracy: 0.7500\n",
            "Epoch 257/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1380 - accuracy: 0.8003 - val_loss: 0.1798 - val_accuracy: 0.7727\n",
            "Epoch 258/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.8101 - val_loss: 0.1807 - val_accuracy: 0.7500\n",
            "Epoch 259/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1363 - accuracy: 0.8087 - val_loss: 0.1668 - val_accuracy: 0.7727\n",
            "Epoch 260/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1381 - accuracy: 0.8101 - val_loss: 0.1835 - val_accuracy: 0.7273\n",
            "Epoch 261/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1376 - accuracy: 0.8087 - val_loss: 0.1836 - val_accuracy: 0.7500\n",
            "Epoch 262/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1380 - accuracy: 0.8170 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
            "Epoch 263/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1361 - accuracy: 0.8101 - val_loss: 0.1689 - val_accuracy: 0.7500\n",
            "Epoch 264/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1377 - accuracy: 0.8087 - val_loss: 0.1720 - val_accuracy: 0.7500\n",
            "Epoch 265/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.8226 - val_loss: 0.1724 - val_accuracy: 0.8182\n",
            "Epoch 266/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.8045 - val_loss: 0.1790 - val_accuracy: 0.7727\n",
            "Epoch 267/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.8059 - val_loss: 0.1804 - val_accuracy: 0.8182\n",
            "Epoch 268/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1364 - accuracy: 0.8059 - val_loss: 0.1687 - val_accuracy: 0.7727\n",
            "Epoch 269/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1370 - accuracy: 0.8128 - val_loss: 0.1791 - val_accuracy: 0.7955\n",
            "Epoch 270/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1359 - accuracy: 0.7989 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
            "Epoch 271/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1370 - accuracy: 0.8059 - val_loss: 0.1732 - val_accuracy: 0.7500\n",
            "Epoch 272/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1358 - accuracy: 0.8087 - val_loss: 0.1850 - val_accuracy: 0.7727\n",
            "Epoch 273/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1367 - accuracy: 0.8045 - val_loss: 0.1777 - val_accuracy: 0.7955\n",
            "Epoch 274/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.8101 - val_loss: 0.1740 - val_accuracy: 0.7500\n",
            "Epoch 275/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1360 - accuracy: 0.8128 - val_loss: 0.1767 - val_accuracy: 0.7727\n",
            "Epoch 276/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.8017 - val_loss: 0.1739 - val_accuracy: 0.7500\n",
            "Epoch 277/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1352 - accuracy: 0.8045 - val_loss: 0.1808 - val_accuracy: 0.7955\n",
            "Epoch 278/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1343 - accuracy: 0.8087 - val_loss: 0.1720 - val_accuracy: 0.7500\n",
            "Epoch 279/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1345 - accuracy: 0.8003 - val_loss: 0.1788 - val_accuracy: 0.7500\n",
            "Epoch 280/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.8059 - val_loss: 0.1769 - val_accuracy: 0.8182\n",
            "Epoch 281/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1355 - accuracy: 0.8142 - val_loss: 0.1702 - val_accuracy: 0.7955\n",
            "Epoch 282/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1346 - accuracy: 0.8031 - val_loss: 0.1775 - val_accuracy: 0.7955\n",
            "Epoch 283/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1357 - accuracy: 0.8142 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
            "Epoch 284/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1357 - accuracy: 0.8045 - val_loss: 0.1706 - val_accuracy: 0.7727\n",
            "Epoch 285/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1334 - accuracy: 0.8128 - val_loss: 0.1821 - val_accuracy: 0.7955\n",
            "Epoch 286/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1353 - accuracy: 0.8156 - val_loss: 0.1727 - val_accuracy: 0.7727\n",
            "Epoch 287/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1352 - accuracy: 0.8184 - val_loss: 0.1726 - val_accuracy: 0.8409\n",
            "Epoch 288/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1333 - accuracy: 0.8198 - val_loss: 0.1713 - val_accuracy: 0.7955\n",
            "Epoch 289/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1342 - accuracy: 0.8115 - val_loss: 0.1856 - val_accuracy: 0.7500\n",
            "Epoch 290/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.8128 - val_loss: 0.1791 - val_accuracy: 0.7955\n",
            "Epoch 291/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1340 - accuracy: 0.8101 - val_loss: 0.1655 - val_accuracy: 0.7955\n",
            "Epoch 292/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1341 - accuracy: 0.8142 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
            "Epoch 293/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1329 - accuracy: 0.8128 - val_loss: 0.1781 - val_accuracy: 0.7955\n",
            "Epoch 294/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1330 - accuracy: 0.8003 - val_loss: 0.1794 - val_accuracy: 0.7727\n",
            "Epoch 295/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1332 - accuracy: 0.8059 - val_loss: 0.1682 - val_accuracy: 0.7955\n",
            "Epoch 296/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1327 - accuracy: 0.8101 - val_loss: 0.1686 - val_accuracy: 0.7727\n",
            "Epoch 297/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1340 - accuracy: 0.8198 - val_loss: 0.1752 - val_accuracy: 0.7955\n",
            "Epoch 298/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1334 - accuracy: 0.8073 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
            "Epoch 299/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1321 - accuracy: 0.8156 - val_loss: 0.1654 - val_accuracy: 0.7955\n",
            "Epoch 300/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.8212 - val_loss: 0.1803 - val_accuracy: 0.7500\n",
            "Epoch 301/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1324 - accuracy: 0.8184 - val_loss: 0.1837 - val_accuracy: 0.7500\n",
            "Epoch 302/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1323 - accuracy: 0.8240 - val_loss: 0.1754 - val_accuracy: 0.7727\n",
            "Epoch 303/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1302 - accuracy: 0.8184 - val_loss: 0.1959 - val_accuracy: 0.7727\n",
            "Epoch 304/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.8226 - val_loss: 0.1701 - val_accuracy: 0.7727\n",
            "Epoch 305/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1331 - accuracy: 0.8156 - val_loss: 0.1802 - val_accuracy: 0.7955\n",
            "Epoch 306/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1313 - accuracy: 0.8184 - val_loss: 0.1845 - val_accuracy: 0.7500\n",
            "Epoch 307/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1316 - accuracy: 0.8087 - val_loss: 0.1895 - val_accuracy: 0.7500\n",
            "Epoch 308/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1324 - accuracy: 0.8128 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
            "Epoch 309/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1322 - accuracy: 0.8128 - val_loss: 0.1698 - val_accuracy: 0.7727\n",
            "Epoch 310/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.8212 - val_loss: 0.1859 - val_accuracy: 0.7727\n",
            "Epoch 311/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1317 - accuracy: 0.8282 - val_loss: 0.1838 - val_accuracy: 0.7955\n",
            "Epoch 312/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1311 - accuracy: 0.8226 - val_loss: 0.1795 - val_accuracy: 0.8409\n",
            "Epoch 313/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.8184 - val_loss: 0.1736 - val_accuracy: 0.7727\n",
            "Epoch 314/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1314 - accuracy: 0.8128 - val_loss: 0.1675 - val_accuracy: 0.8182\n",
            "Epoch 315/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1303 - accuracy: 0.8226 - val_loss: 0.1798 - val_accuracy: 0.7727\n",
            "Epoch 316/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.8212 - val_loss: 0.1939 - val_accuracy: 0.7955\n",
            "Epoch 317/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1307 - accuracy: 0.8212 - val_loss: 0.1720 - val_accuracy: 0.8409\n",
            "Epoch 318/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1305 - accuracy: 0.8268 - val_loss: 0.1786 - val_accuracy: 0.7955\n",
            "Epoch 319/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1293 - accuracy: 0.8282 - val_loss: 0.1764 - val_accuracy: 0.7727\n",
            "Epoch 320/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.8101 - val_loss: 0.1916 - val_accuracy: 0.7500\n",
            "Epoch 321/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1300 - accuracy: 0.8128 - val_loss: 0.1817 - val_accuracy: 0.7500\n",
            "Epoch 322/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1299 - accuracy: 0.8073 - val_loss: 0.1878 - val_accuracy: 0.7500\n",
            "Epoch 323/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1310 - accuracy: 0.8254 - val_loss: 0.1763 - val_accuracy: 0.7727\n",
            "Epoch 324/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.8212 - val_loss: 0.1653 - val_accuracy: 0.7955\n",
            "Epoch 325/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1292 - accuracy: 0.8240 - val_loss: 0.1739 - val_accuracy: 0.7727\n",
            "Epoch 326/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1297 - accuracy: 0.8240 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
            "Epoch 327/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1282 - accuracy: 0.8198 - val_loss: 0.1607 - val_accuracy: 0.7727\n",
            "Epoch 328/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.8212 - val_loss: 0.1794 - val_accuracy: 0.7727\n",
            "Epoch 329/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1295 - accuracy: 0.8142 - val_loss: 0.1675 - val_accuracy: 0.7955\n",
            "Epoch 330/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1292 - accuracy: 0.8212 - val_loss: 0.1700 - val_accuracy: 0.7727\n",
            "Epoch 331/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1286 - accuracy: 0.8212 - val_loss: 0.1788 - val_accuracy: 0.7273\n",
            "Epoch 332/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1284 - accuracy: 0.8268 - val_loss: 0.1769 - val_accuracy: 0.7955\n",
            "Epoch 333/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.8296 - val_loss: 0.1784 - val_accuracy: 0.7955\n",
            "Epoch 334/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.8240 - val_loss: 0.1744 - val_accuracy: 0.8182\n",
            "Epoch 335/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1277 - accuracy: 0.8170 - val_loss: 0.1808 - val_accuracy: 0.8182\n",
            "Epoch 336/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.8240 - val_loss: 0.1762 - val_accuracy: 0.7727\n",
            "Epoch 337/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1288 - accuracy: 0.8310 - val_loss: 0.1765 - val_accuracy: 0.7955\n",
            "Epoch 338/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.8352 - val_loss: 0.1802 - val_accuracy: 0.7500\n",
            "Epoch 339/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1283 - accuracy: 0.8268 - val_loss: 0.1773 - val_accuracy: 0.7955\n",
            "Epoch 340/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1272 - accuracy: 0.8198 - val_loss: 0.1815 - val_accuracy: 0.7955\n",
            "Epoch 341/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1276 - accuracy: 0.8142 - val_loss: 0.1806 - val_accuracy: 0.7500\n",
            "Epoch 342/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1264 - accuracy: 0.8240 - val_loss: 0.1721 - val_accuracy: 0.7500\n",
            "Epoch 343/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1278 - accuracy: 0.8282 - val_loss: 0.1725 - val_accuracy: 0.7727\n",
            "Epoch 344/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.8282 - val_loss: 0.1721 - val_accuracy: 0.8182\n",
            "Epoch 345/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1290 - accuracy: 0.8198 - val_loss: 0.1720 - val_accuracy: 0.7955\n",
            "Epoch 346/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1270 - accuracy: 0.8268 - val_loss: 0.1772 - val_accuracy: 0.7955\n",
            "Epoch 347/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1281 - accuracy: 0.8184 - val_loss: 0.1702 - val_accuracy: 0.7955\n",
            "Epoch 348/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.8226 - val_loss: 0.1708 - val_accuracy: 0.7955\n",
            "Epoch 349/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.8198 - val_loss: 0.1771 - val_accuracy: 0.7955\n",
            "Epoch 350/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.8226 - val_loss: 0.1906 - val_accuracy: 0.7955\n",
            "Epoch 351/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.8184 - val_loss: 0.1727 - val_accuracy: 0.7727\n",
            "Epoch 352/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.8198 - val_loss: 0.1838 - val_accuracy: 0.7727\n",
            "Epoch 353/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1269 - accuracy: 0.8198 - val_loss: 0.1718 - val_accuracy: 0.7727\n",
            "Epoch 354/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.8296 - val_loss: 0.1694 - val_accuracy: 0.7955\n",
            "Epoch 355/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.8184 - val_loss: 0.1783 - val_accuracy: 0.8182\n",
            "Epoch 356/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.8310 - val_loss: 0.1800 - val_accuracy: 0.7727\n",
            "Epoch 357/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.8254 - val_loss: 0.1780 - val_accuracy: 0.7955\n",
            "Epoch 358/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1255 - accuracy: 0.8268 - val_loss: 0.1675 - val_accuracy: 0.7500\n",
            "Epoch 359/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1262 - accuracy: 0.8240 - val_loss: 0.1709 - val_accuracy: 0.7955\n",
            "Epoch 360/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1264 - accuracy: 0.8184 - val_loss: 0.1823 - val_accuracy: 0.7955\n",
            "Epoch 361/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1258 - accuracy: 0.8310 - val_loss: 0.1759 - val_accuracy: 0.7727\n",
            "Epoch 362/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.8240 - val_loss: 0.1678 - val_accuracy: 0.7955\n",
            "Epoch 363/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1257 - accuracy: 0.8170 - val_loss: 0.1773 - val_accuracy: 0.7955\n",
            "Epoch 364/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.8268 - val_loss: 0.1704 - val_accuracy: 0.7955\n",
            "Epoch 365/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1249 - accuracy: 0.8282 - val_loss: 0.1823 - val_accuracy: 0.7955\n",
            "Epoch 366/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1252 - accuracy: 0.8254 - val_loss: 0.1690 - val_accuracy: 0.7955\n",
            "Epoch 367/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1247 - accuracy: 0.8268 - val_loss: 0.1771 - val_accuracy: 0.8636\n",
            "Epoch 368/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1250 - accuracy: 0.8338 - val_loss: 0.1661 - val_accuracy: 0.7727\n",
            "Epoch 369/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.8254 - val_loss: 0.1853 - val_accuracy: 0.7955\n",
            "Epoch 370/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1245 - accuracy: 0.8366 - val_loss: 0.1753 - val_accuracy: 0.8182\n",
            "Epoch 371/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1247 - accuracy: 0.8268 - val_loss: 0.1792 - val_accuracy: 0.7727\n",
            "Epoch 372/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1250 - accuracy: 0.8198 - val_loss: 0.1715 - val_accuracy: 0.7955\n",
            "Epoch 373/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1236 - accuracy: 0.8240 - val_loss: 0.1686 - val_accuracy: 0.8182\n",
            "Epoch 374/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1238 - accuracy: 0.8324 - val_loss: 0.1703 - val_accuracy: 0.8182\n",
            "Epoch 375/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1243 - accuracy: 0.8212 - val_loss: 0.1766 - val_accuracy: 0.7955\n",
            "Epoch 376/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1241 - accuracy: 0.8338 - val_loss: 0.1685 - val_accuracy: 0.7955\n",
            "Epoch 377/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1245 - accuracy: 0.8226 - val_loss: 0.1840 - val_accuracy: 0.7727\n",
            "Epoch 378/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1229 - accuracy: 0.8338 - val_loss: 0.1738 - val_accuracy: 0.7955\n",
            "Epoch 379/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.8338 - val_loss: 0.1768 - val_accuracy: 0.7955\n",
            "Epoch 380/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.8310 - val_loss: 0.1774 - val_accuracy: 0.7955\n",
            "Epoch 381/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1243 - accuracy: 0.8296 - val_loss: 0.1803 - val_accuracy: 0.7955\n",
            "Epoch 382/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.8352 - val_loss: 0.1758 - val_accuracy: 0.7955\n",
            "Epoch 383/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1242 - accuracy: 0.8408 - val_loss: 0.1743 - val_accuracy: 0.8182\n",
            "Epoch 384/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1230 - accuracy: 0.8310 - val_loss: 0.1762 - val_accuracy: 0.7955\n",
            "Epoch 385/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.8352 - val_loss: 0.1711 - val_accuracy: 0.7955\n",
            "Epoch 386/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1225 - accuracy: 0.8310 - val_loss: 0.1694 - val_accuracy: 0.7955\n",
            "Epoch 387/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1223 - accuracy: 0.8352 - val_loss: 0.1717 - val_accuracy: 0.8182\n",
            "Epoch 388/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1225 - accuracy: 0.8338 - val_loss: 0.1855 - val_accuracy: 0.7955\n",
            "Epoch 389/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1224 - accuracy: 0.8338 - val_loss: 0.1753 - val_accuracy: 0.7955\n",
            "Epoch 390/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1221 - accuracy: 0.8366 - val_loss: 0.1820 - val_accuracy: 0.7955\n",
            "Epoch 391/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1218 - accuracy: 0.8310 - val_loss: 0.1663 - val_accuracy: 0.7955\n",
            "Epoch 392/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1226 - accuracy: 0.8338 - val_loss: 0.1724 - val_accuracy: 0.7955\n",
            "Epoch 393/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.8394 - val_loss: 0.1688 - val_accuracy: 0.7955\n",
            "Epoch 394/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1217 - accuracy: 0.8380 - val_loss: 0.1807 - val_accuracy: 0.7955\n",
            "Epoch 395/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1227 - accuracy: 0.8338 - val_loss: 0.1747 - val_accuracy: 0.8182\n",
            "Epoch 396/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1221 - accuracy: 0.8408 - val_loss: 0.1719 - val_accuracy: 0.7727\n",
            "Epoch 397/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1222 - accuracy: 0.8268 - val_loss: 0.1817 - val_accuracy: 0.7955\n",
            "Epoch 398/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1220 - accuracy: 0.8310 - val_loss: 0.1783 - val_accuracy: 0.8182\n",
            "Epoch 399/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.8464 - val_loss: 0.1845 - val_accuracy: 0.7955\n",
            "Epoch 400/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1216 - accuracy: 0.8380 - val_loss: 0.1866 - val_accuracy: 0.7955\n",
            "Epoch 401/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1219 - accuracy: 0.8352 - val_loss: 0.1765 - val_accuracy: 0.7955\n",
            "Epoch 402/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1203 - accuracy: 0.8436 - val_loss: 0.1696 - val_accuracy: 0.8182\n",
            "Epoch 403/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1208 - accuracy: 0.8366 - val_loss: 0.1769 - val_accuracy: 0.7955\n",
            "Epoch 404/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1208 - accuracy: 0.8352 - val_loss: 0.1707 - val_accuracy: 0.7955\n",
            "Epoch 405/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1214 - accuracy: 0.8352 - val_loss: 0.1922 - val_accuracy: 0.7955\n",
            "Epoch 406/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1206 - accuracy: 0.8282 - val_loss: 0.1859 - val_accuracy: 0.7727\n",
            "Epoch 407/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1207 - accuracy: 0.8436 - val_loss: 0.1815 - val_accuracy: 0.7955\n",
            "Epoch 408/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1205 - accuracy: 0.8422 - val_loss: 0.1910 - val_accuracy: 0.7955\n",
            "Epoch 409/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1205 - accuracy: 0.8394 - val_loss: 0.1849 - val_accuracy: 0.8182\n",
            "Epoch 410/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1193 - accuracy: 0.8352 - val_loss: 0.1762 - val_accuracy: 0.8182\n",
            "Epoch 411/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1208 - accuracy: 0.8352 - val_loss: 0.1790 - val_accuracy: 0.7955\n",
            "Epoch 412/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.8366 - val_loss: 0.1866 - val_accuracy: 0.8182\n",
            "Epoch 413/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1188 - accuracy: 0.8422 - val_loss: 0.1875 - val_accuracy: 0.7955\n",
            "Epoch 414/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1209 - accuracy: 0.8324 - val_loss: 0.1894 - val_accuracy: 0.7955\n",
            "Epoch 415/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1200 - accuracy: 0.8366 - val_loss: 0.1791 - val_accuracy: 0.8182\n",
            "Epoch 416/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.8310 - val_loss: 0.1815 - val_accuracy: 0.7955\n",
            "Epoch 417/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1204 - accuracy: 0.8422 - val_loss: 0.1930 - val_accuracy: 0.7727\n",
            "Epoch 418/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1195 - accuracy: 0.8352 - val_loss: 0.1863 - val_accuracy: 0.8182\n",
            "Epoch 419/500\n",
            "716/716 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.8394 - val_loss: 0.1801 - val_accuracy: 0.7955\n",
            "Epoch 420/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1201 - accuracy: 0.8338 - val_loss: 0.1747 - val_accuracy: 0.7955\n",
            "Epoch 421/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1194 - accuracy: 0.8394 - val_loss: 0.1831 - val_accuracy: 0.7955\n",
            "Epoch 422/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1190 - accuracy: 0.8366 - val_loss: 0.1779 - val_accuracy: 0.8182\n",
            "Epoch 423/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1199 - accuracy: 0.8380 - val_loss: 0.1735 - val_accuracy: 0.8182\n",
            "Epoch 424/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.8520 - val_loss: 0.1765 - val_accuracy: 0.7955\n",
            "Epoch 425/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1182 - accuracy: 0.8450 - val_loss: 0.1829 - val_accuracy: 0.8182\n",
            "Epoch 426/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1193 - accuracy: 0.8268 - val_loss: 0.1878 - val_accuracy: 0.8182\n",
            "Epoch 427/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.8422 - val_loss: 0.1858 - val_accuracy: 0.7955\n",
            "Epoch 428/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1191 - accuracy: 0.8506 - val_loss: 0.1790 - val_accuracy: 0.7955\n",
            "Epoch 429/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1195 - accuracy: 0.8380 - val_loss: 0.1736 - val_accuracy: 0.7955\n",
            "Epoch 430/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1172 - accuracy: 0.8464 - val_loss: 0.1814 - val_accuracy: 0.8182\n",
            "Epoch 431/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1187 - accuracy: 0.8366 - val_loss: 0.1819 - val_accuracy: 0.7955\n",
            "Epoch 432/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.8394 - val_loss: 0.1732 - val_accuracy: 0.7727\n",
            "Epoch 433/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1179 - accuracy: 0.8450 - val_loss: 0.1783 - val_accuracy: 0.7955\n",
            "Epoch 434/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1184 - accuracy: 0.8464 - val_loss: 0.1719 - val_accuracy: 0.7955\n",
            "Epoch 435/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1182 - accuracy: 0.8450 - val_loss: 0.1765 - val_accuracy: 0.8182\n",
            "Epoch 436/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1167 - accuracy: 0.8450 - val_loss: 0.1901 - val_accuracy: 0.7955\n",
            "Epoch 437/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1174 - accuracy: 0.8324 - val_loss: 0.1784 - val_accuracy: 0.7955\n",
            "Epoch 438/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.8464 - val_loss: 0.1708 - val_accuracy: 0.7955\n",
            "Epoch 439/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.8366 - val_loss: 0.1729 - val_accuracy: 0.7955\n",
            "Epoch 440/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1179 - accuracy: 0.8464 - val_loss: 0.1829 - val_accuracy: 0.8182\n",
            "Epoch 441/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1181 - accuracy: 0.8408 - val_loss: 0.1779 - val_accuracy: 0.7955\n",
            "Epoch 442/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1175 - accuracy: 0.8464 - val_loss: 0.1814 - val_accuracy: 0.7955\n",
            "Epoch 443/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1174 - accuracy: 0.8380 - val_loss: 0.1779 - val_accuracy: 0.7955\n",
            "Epoch 444/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1178 - accuracy: 0.8408 - val_loss: 0.1853 - val_accuracy: 0.7955\n",
            "Epoch 445/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1172 - accuracy: 0.8492 - val_loss: 0.1949 - val_accuracy: 0.7955\n",
            "Epoch 446/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1168 - accuracy: 0.8338 - val_loss: 0.1790 - val_accuracy: 0.7955\n",
            "Epoch 447/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.8547 - val_loss: 0.1789 - val_accuracy: 0.8182\n",
            "Epoch 448/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1166 - accuracy: 0.8520 - val_loss: 0.1828 - val_accuracy: 0.8182\n",
            "Epoch 449/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1162 - accuracy: 0.8464 - val_loss: 0.1910 - val_accuracy: 0.7955\n",
            "Epoch 450/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1179 - accuracy: 0.8422 - val_loss: 0.1850 - val_accuracy: 0.7955\n",
            "Epoch 451/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1162 - accuracy: 0.8408 - val_loss: 0.1766 - val_accuracy: 0.7955\n",
            "Epoch 452/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1162 - accuracy: 0.8506 - val_loss: 0.1744 - val_accuracy: 0.8182\n",
            "Epoch 453/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1162 - accuracy: 0.8408 - val_loss: 0.1950 - val_accuracy: 0.7955\n",
            "Epoch 454/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1161 - accuracy: 0.8534 - val_loss: 0.1988 - val_accuracy: 0.7955\n",
            "Epoch 455/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1162 - accuracy: 0.8478 - val_loss: 0.1795 - val_accuracy: 0.7955\n",
            "Epoch 456/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1163 - accuracy: 0.8436 - val_loss: 0.1763 - val_accuracy: 0.7955\n",
            "Epoch 457/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1154 - accuracy: 0.8520 - val_loss: 0.1839 - val_accuracy: 0.7955\n",
            "Epoch 458/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1169 - accuracy: 0.8436 - val_loss: 0.1748 - val_accuracy: 0.8182\n",
            "Epoch 459/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1164 - accuracy: 0.8450 - val_loss: 0.1781 - val_accuracy: 0.8182\n",
            "Epoch 460/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1154 - accuracy: 0.8436 - val_loss: 0.1856 - val_accuracy: 0.7955\n",
            "Epoch 461/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.8561 - val_loss: 0.1759 - val_accuracy: 0.7955\n",
            "Epoch 462/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1161 - accuracy: 0.8589 - val_loss: 0.1805 - val_accuracy: 0.7955\n",
            "Epoch 463/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1150 - accuracy: 0.8506 - val_loss: 0.1860 - val_accuracy: 0.8182\n",
            "Epoch 464/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1159 - accuracy: 0.8464 - val_loss: 0.1802 - val_accuracy: 0.8182\n",
            "Epoch 465/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1155 - accuracy: 0.8561 - val_loss: 0.1927 - val_accuracy: 0.8182\n",
            "Epoch 466/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1140 - accuracy: 0.8478 - val_loss: 0.1765 - val_accuracy: 0.7955\n",
            "Epoch 467/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1148 - accuracy: 0.8561 - val_loss: 0.1831 - val_accuracy: 0.7955\n",
            "Epoch 468/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1151 - accuracy: 0.8422 - val_loss: 0.1875 - val_accuracy: 0.7955\n",
            "Epoch 469/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1141 - accuracy: 0.8561 - val_loss: 0.1865 - val_accuracy: 0.7955\n",
            "Epoch 470/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1137 - accuracy: 0.8492 - val_loss: 0.1791 - val_accuracy: 0.7955\n",
            "Epoch 471/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.8520 - val_loss: 0.1828 - val_accuracy: 0.8182\n",
            "Epoch 472/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1136 - accuracy: 0.8520 - val_loss: 0.1889 - val_accuracy: 0.7955\n",
            "Epoch 473/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1145 - accuracy: 0.8506 - val_loss: 0.2006 - val_accuracy: 0.7955\n",
            "Epoch 474/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1151 - accuracy: 0.8631 - val_loss: 0.1906 - val_accuracy: 0.8182\n",
            "Epoch 475/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.8492 - val_loss: 0.1861 - val_accuracy: 0.7955\n",
            "Epoch 476/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1139 - accuracy: 0.8547 - val_loss: 0.1909 - val_accuracy: 0.7955\n",
            "Epoch 477/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1140 - accuracy: 0.8520 - val_loss: 0.1787 - val_accuracy: 0.7955\n",
            "Epoch 478/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1144 - accuracy: 0.8520 - val_loss: 0.1798 - val_accuracy: 0.7955\n",
            "Epoch 479/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1132 - accuracy: 0.8408 - val_loss: 0.1774 - val_accuracy: 0.7955\n",
            "Epoch 480/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1137 - accuracy: 0.8520 - val_loss: 0.1880 - val_accuracy: 0.7955\n",
            "Epoch 481/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1137 - accuracy: 0.8450 - val_loss: 0.1839 - val_accuracy: 0.7955\n",
            "Epoch 482/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1134 - accuracy: 0.8534 - val_loss: 0.1844 - val_accuracy: 0.7955\n",
            "Epoch 483/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1133 - accuracy: 0.8561 - val_loss: 0.1940 - val_accuracy: 0.8182\n",
            "Epoch 484/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1135 - accuracy: 0.8492 - val_loss: 0.1937 - val_accuracy: 0.7955\n",
            "Epoch 485/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1130 - accuracy: 0.8436 - val_loss: 0.1853 - val_accuracy: 0.7955\n",
            "Epoch 486/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1127 - accuracy: 0.8464 - val_loss: 0.1792 - val_accuracy: 0.7955\n",
            "Epoch 487/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1129 - accuracy: 0.8520 - val_loss: 0.1823 - val_accuracy: 0.8182\n",
            "Epoch 488/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1124 - accuracy: 0.8589 - val_loss: 0.1801 - val_accuracy: 0.7955\n",
            "Epoch 489/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1130 - accuracy: 0.8506 - val_loss: 0.1911 - val_accuracy: 0.7955\n",
            "Epoch 490/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1116 - accuracy: 0.8631 - val_loss: 0.1875 - val_accuracy: 0.8182\n",
            "Epoch 491/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1123 - accuracy: 0.8547 - val_loss: 0.1869 - val_accuracy: 0.7955\n",
            "Epoch 492/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1121 - accuracy: 0.8478 - val_loss: 0.1949 - val_accuracy: 0.7955\n",
            "Epoch 493/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1136 - accuracy: 0.8534 - val_loss: 0.1852 - val_accuracy: 0.7955\n",
            "Epoch 494/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1115 - accuracy: 0.8547 - val_loss: 0.1887 - val_accuracy: 0.7955\n",
            "Epoch 495/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1119 - accuracy: 0.8561 - val_loss: 0.1846 - val_accuracy: 0.8182\n",
            "Epoch 496/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1132 - accuracy: 0.8561 - val_loss: 0.1824 - val_accuracy: 0.7955\n",
            "Epoch 497/500\n",
            "716/716 [==============================] - 4s 5ms/step - loss: 0.1118 - accuracy: 0.8575 - val_loss: 0.1878 - val_accuracy: 0.7727\n",
            "Epoch 498/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.8547 - val_loss: 0.1950 - val_accuracy: 0.7955\n",
            "Epoch 499/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1123 - accuracy: 0.8561 - val_loss: 0.1907 - val_accuracy: 0.7955\n",
            "Epoch 500/500\n",
            "716/716 [==============================] - 3s 5ms/step - loss: 0.1114 - accuracy: 0.8534 - val_loss: 0.1967 - val_accuracy: 0.7955\n"
          ]
        }
      ],
      "source": [
        "# Calling ANFIS with parameters\n",
        "fis = myanfis.ANFIS(n_input = param.n_input,\n",
        "              n_memb = param.n_memb,\n",
        "              batch_size = param.batch_size,\n",
        "              memb_func = param.memb_func,\n",
        "              name = 'firstAnfis'\n",
        "              )\n",
        "\n",
        "# Compile model\n",
        "fis.model.compile(optimizer=param.optimizer,\n",
        "                loss=param.loss,\n",
        "                metrics=['accuracy']  # ['mae', 'mse']\n",
        "                )\n",
        "\n",
        "# Fit model\n",
        "history = fis.fit(X_train, Y_train,\n",
        "            epochs=param.n_epochs,\n",
        "            batch_size=param.batch_size,\n",
        "            #validation_split=0.1,\n",
        "            validation_data = (X_test, Y_test),\n",
        "            )\n",
        "# Append training results to history\n",
        "histories = []\n",
        "histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zHaDOYT2Mwi"
      },
      "outputs": [],
      "source": [
        "# Plot model performance\n",
        "\n",
        "loss_curves = pd.DataFrame(history.history)\n",
        "loss_curves.plot(figsize=(8, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U23EFwBQLfsY"
      },
      "outputs": [],
      "source": [
        "# ------------------------- END ----------------------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}